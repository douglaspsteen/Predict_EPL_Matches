{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Doug Steen\n",
    "* Student pace: Full time\n",
    "* Scheduled project review date/time: 2/8/2020, 11:30 AM CT\n",
    "* Instructor name: James Irving, PhD\n",
    "* Blog post URL: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Machine Learning Algorithms Used\n",
    "#### k-Nearest Neighbors (kNN)\n",
    "kNN is a supervised algorithm that can be used for classification or regression problems. In classification, the algorithm predicts test class labels based on the distance to the nearest k training examples in n-dimensional feature space.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "#### Decision Trees\n",
    "A Decision Tree is a supervised algorithm that can be used for classification or regression problems. In classification, a Decision Tree is constructed using the training data to incrementally partition examples using features that maximize information gain (with respect to training labels) at each step. Labels for test data are then predicted using the Decision Tree constructed from the training data.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "#### Random Forest\n",
    "A Random Forest is a Decision Tree-based supervised learning ensemble method. Random Forests can be used for classification or regression problems. A Random Forest includes many Decision Trees that each utilize (1) a bootstrap-sampled version of the original dataset and (2) random subsets of the dataset features. In classification problems, each of the Decision Trees in the Random Forest get a 'vote' towards the classification of each example in the test dataset. This method helps counteract the 'overfitting' that can take place when using a single Decision Tree.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "#### AdaBoost\n",
    "AdaBoost (short for 'Adaptive Boosting') is a Decision-Tree-based supervised learning ensemble method. AdaBoost can be used for classification or regression problems. An AdaBoost algorithm includes many Decision Trees that are 'weak learners' (i.e., each tree has a depth of 1). Unlike a Random Forest, the trees in AdaBoost are trained sequentially, so that examples that were misclassified in previous trees are more heavily weighted in subsequent trees. This method also helps counteract the 'overfitting' that can take place when using a single Decision Tree.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\n",
    "\n",
    "#### XGBoost\n",
    "XGBoost (short for eXtreme Gradient Boost)\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U fsds_100719\n",
    "#!pip install imblearn\n",
    "import warnings\n",
    "from fsds_100719.imports import *\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas_profiling as pp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, plot_confusion_matrix, roc_auc_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "from pydotplus import graph_from_dot_data\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "# Display all columns of large dataframes\n",
    "pd.set_option('display.max_columns', 0)\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set default plot style & inline plotting\n",
    "plt.style.use('seaborn-dark')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_SMOTE(X, y, n, random_state, verbose=1):\n",
    "    \"\"\"Using imblearn.over_sampling.SMOTE, performs (n-1) iterations of SMOTE to facilitate creating balanced target classes when multiple classes are present.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like\n",
    "        Matrix containing the feature data to be sampled\n",
    "    y : array-like (1-d)\n",
    "        Corresponding target labels for each sample in X\n",
    "    n : int\n",
    "        Number of unique classes/labels in y\n",
    "    random_state : int\n",
    "        Value to set as the random_state for SMOTE function reproducibility\n",
    "    verbose : int (1 or 2)\n",
    "        If 1, prints label counts only after final SMOTE iteration\n",
    "        If 2, prints label counts at each SMOTE iteration (including initial)\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_resampled : array-like\n",
    "        Matrix containing the resampled feature data\n",
    "    y_resampled : array-like (1-d)\n",
    "        Corresponding target labels for X_resampled\n",
    "    \"\"\"\n",
    "\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    import pandas as pd\n",
    "\n",
    "    # Initialize a SMOTE object\n",
    "    smote = SMOTE(random_state=random_state)\n",
    "\n",
    "    # Output if verbose = 2\n",
    "    if verbose == 2:\n",
    "        print(f'Label counts for Original y:\\n{pd.Series(y).value_counts()}')\n",
    "\n",
    "    # Perform SMOTE n-1 times to achieve balanced target classes\n",
    "    for i in range(n - 1):\n",
    "        X, y = smote.fit_sample(X, y)\n",
    "\n",
    "        # Print value counts after each step if verbose == 2\n",
    "        if verbose == 2:\n",
    "            print(\n",
    "                f'Label counts after SMOTE # {i+1}:\\n{pd.Series(y).value_counts()}')\n",
    "\n",
    "    # Print final value counts if verbose == 1\n",
    "    if verbose == 1:\n",
    "        print(\n",
    "            f'Label counts after SMOTE # {n-1}:\\n{pd.Series(y).value_counts()}')\n",
    "\n",
    "    X_resampled = X\n",
    "    y_resampled = y\n",
    "\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "\n",
    "def train_test_acc_auc(X_train, X_test, y_train, y_test, y_hat_train, y_hat_test, clf, multi_class=False):\n",
    "    \"\"\"Returns classification accuracy score and ROC AUC score for both train and test data after train-test-split.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train : array-like\n",
    "        Matrix containing the training feature data    \n",
    "    X_test : array-like\n",
    "        Matrix containing the testing feature data\n",
    "    y_train : array-like (1-d)\n",
    "        Corresponding target labels for each sample in X_train\n",
    "    y_test : array-like (1-d)\n",
    "        Corresponding target labels for each sample in X_test\n",
    "    y_hat_train : array-like (1-d)\n",
    "        Model predictions for each sample in X_train\n",
    "    y_hat_test : array-like (1-d)\n",
    "        Model predictions for each sample in X_test\n",
    "    clf : Sklearn-type classifier object\n",
    "        Classifier used to generate model predictions\n",
    "    multi_class : Bool\n",
    "        If True, computes AUC for multi-class classification problem\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    Accuracy score and ROC AUC score for both training and test data.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "    test_acc = accuracy_score(y_test, y_hat_test)\n",
    "    train_acc = accuracy_score(y_train, y_hat_train)\n",
    "\n",
    "    if multi_class:\n",
    "        y_score_train = clf.predict_proba(X_train)\n",
    "        auc_train = roc_auc_score(\n",
    "            y_train, y_score=y_score_train, multi_class='ovr')\n",
    "\n",
    "        y_score_test = clf.predict_proba(X_test)\n",
    "        auc_test = roc_auc_score(\n",
    "            y_test, y_score=y_score_test, multi_class='ovr')\n",
    "\n",
    "    else:\n",
    "        y_score_train = clf.predict_proba(X_train)\n",
    "        auc_train = roc_auc_score(y_train, y_score=y_score_train)\n",
    "\n",
    "        y_score_test = clf.predict_proba(X_test)\n",
    "        auc_test = roc_auc_score(y_test, y_score=y_score_test)\n",
    "\n",
    "    print(f'Training Accuracy Score: {round(train_acc,2)}')\n",
    "    print(f'Training AUC: {round(auc_train,2)}\\n')\n",
    "    print(f'Testing Accuracy Score: {round(test_acc,2)}')\n",
    "    print(f'Testing AUC: {round(auc_test,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load dataset from directory (obtained in separate notebook using api-football calls)\n",
    "\n",
    "df = pd.read_csv('premier_league.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrub/Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an idea of datatypes in the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate columns that will not be important for the classification model\n",
    "to_drop = ['league_id', 'league', 'event_date', 'event_timestamp', 'firstHalfStart', 'secondHalfStart',\n",
    "           'round', 'status', 'statusShort', 'venue', 'referee', 'homeTeam', 'awayTeam', 'elapsed', 'score']\n",
    "\n",
    "df = df.drop(to_drop, axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run pandas profiling for inital EDA\n",
    "\n",
    "pp.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Missing values for Blocked Shots, Goalkeeper Saves, Offsides, Passes %, Red Cards, Yellow Cards\n",
    "\n",
    "# Going to fill each (except Passes %) with median value for that column\n",
    "\n",
    "fill_cols = ['Blocked_Shots', 'Goalkeeper_Saves',\n",
    "             'Offsides', 'Red_Cards', 'Yellow_Cards']\n",
    "\n",
    "for col in fill_cols:\n",
    "    df[col].fillna(value=df[col].median(), inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-cast object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert team column to binary (0 = Home, 1 = Away)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df['team'][i] == 'home':\n",
    "        df['team'][i] = 0\n",
    "    elif df['team'][i] == 'away':\n",
    "        df['team'][i] = 1\n",
    "\n",
    "df.team = df.team.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip % from Ball Possession and re-cast as a numerical variable\n",
    "\n",
    "df['Ball_Possession'] = df['Ball_Possession'].str.rstrip('%').astype('int')\n",
    "df['Ball_Possession']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Re-calculate Passes (%) as Passes accurate / Total passes to handle missing values\n",
    "\n",
    "df['Passes_%'] = df['Passes_accurate'] / df['Total_passes']\n",
    "df['Passes_%']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapse df to one row per match (instead of one row per team per match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataframe for only home team stats\n",
    "\n",
    "df_home = df.loc[df.team == 0]\n",
    "df_home.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename df_home columns before concatenation\n",
    "\n",
    "for col in df_home.columns:\n",
    "    df_home.rename(columns={col: f'{col}_H'}, inplace=True)\n",
    "\n",
    "df_home.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset indes of df_home\n",
    "df_home.set_index('fixture_id_H', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for only away team stats\n",
    "\n",
    "df_away = df[df.team == 1]\n",
    "df_away.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename df_away columns before concatenation\n",
    "\n",
    "for col in df_away.columns:\n",
    "    df_away.rename(columns={col: f'{col}_A'}, inplace=True)\n",
    "\n",
    "df_away.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index of df_away\n",
    "df_away.set_index('fixture_id_A', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate df_home and df_away dataframes\n",
    "\n",
    "df_final = pd.concat([df_home, df_away], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create target variable (class labels)\n",
    "\n",
    "0 = Home Team Win, 1 = Away Team Win, 2 = Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable column: 0 = Win, 1 = Loss, 2 = Draw\n",
    "\n",
    "target = []\n",
    "for i in range(len(df_final)):\n",
    "    if df_final['goalsHomeTeam_H'].iloc[i] > df_final['goalsAwayTeam_H'].iloc[i]:\n",
    "        target.append(0)  # Home team win\n",
    "    elif df_final['goalsHomeTeam_H'].iloc[i] < df_final['goalsAwayTeam_H'].iloc[i]:\n",
    "        target.append(1)  # Away team win\n",
    "    elif df_final['goalsHomeTeam_H'].iloc[i] == df_final['goalsAwayTeam_H'].iloc[i]:\n",
    "        target.append(2)  # Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineer new column: Ball_Pos_Diff as Ball_Possession_H - Ball_Possession_A\n",
    "# These two columns are going to be perfectly negatively correlated, so makes sense to collapse them\n",
    "\n",
    "df_final['Ball_Pos_Diff'] = df_final['Ball_Possession_H'] - \\\n",
    "    df_final['Ball_Possession_A']\n",
    "df_final.drop(['Ball_Possession_H', 'Ball_Possession_A'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final drop of unnecessary columns from df_diff (fixture_id remaining as index)\n",
    "\n",
    "df_final.drop(['team_H', 'goalsHomeTeam_H', 'goalsAwayTeam_H',\n",
    "               'team_A', 'goalsHomeTeam_A', 'goalsAwayTeam_A'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check class imbalance of dataset\n",
    "\n",
    "df_final.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels dictionary for future use\n",
    "\n",
    "labels = {'Home Win': 0, 'Away Win': 1, 'Draw': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize pandas profiling again\n",
    "\n",
    "pp.ProfileReport(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models & Interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1a: Vanilla K Nearest Neighbors (KNN) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target labels\n",
    "\n",
    "X = df_final.drop('target', axis=1)\n",
    "y = df_final['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train_test split on the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale X data before passing to KNN algorithm\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Synthetic Minority Over-Sampling Technique (SMOTE) to achieve class balance\n",
    "\n",
    "X_train, y_train = multi_class_SMOTE(\n",
    "    X_train, y_train, n=3, random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a vanilla KNN classifier\n",
    "\n",
    "clf1a = KNeighborsClassifier()\n",
    "clf1a.fit(X_train, y_train)\n",
    "\n",
    "y_hat_test = clf1a.predict(X_test)\n",
    "y_hat_train = clf1a.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy score and AUC score of vanilla KNN model\n",
    "\n",
    "train_test_acc_auc(X_train, X_test, y_train, y_test, y_hat_train, y_hat_test, clf=clf1a,\n",
    "                   multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classification report of vanilla KNN model\n",
    "\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix for vanilla KNN model\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(clf1a, X_test, y_test, cmap='Greens', display_labels=labels.keys(),\n",
    "                      normalize='true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1a Interpretation\n",
    "The vanilla KNN classifier performs poorly for this task, with a test AUC of 0.63 and a test accuracy score of 0.43. This classifier is therefore only slightly better than guessing (which would be 33% accuracy) for this 3-class classification problem. \n",
    "\n",
    "The classifier correctly labeled 45% of True Home Wins, 47% of True Away Wins, and only 31% of True Draws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1b: KNN Classifier with Hyperparameter tuning of k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Trying many values for n_neighbors parameter to improve overall AUC (uncomment to run)\n",
    "\n",
    "k_neighbors = range(1, 200)\n",
    "\n",
    "train_auc_list = []\n",
    "test_auc_list = []\n",
    "\n",
    "for i in k_neighbors:\n",
    "    clf1b = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf1b.fit(X_train, y_train)\n",
    "    y_hat_test = clf1b.predict(X_test)\n",
    "    y_hat_train = clf1b.predict(X_train)\n",
    "\n",
    "    y_score_train = clf1b.predict_proba(X_train)\n",
    "    auc_train = roc_auc_score(\n",
    "        y_train, y_score=y_score_train, multi_class='ovr')\n",
    "    y_score_test = clf1b.predict_proba(X_test)\n",
    "    auc_test = roc_auc_score(y_test, y_score=y_score_test, multi_class='ovr')\n",
    "\n",
    "    train_auc_list.append(auc_train)\n",
    "    test_auc_list.append(auc_test)\n",
    "\n",
    "print(train_auc_list)\n",
    "print(test_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure to visualize how train-test AUC change with # of Neighbors in KNN\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(k_neighbors, train_auc_list, label='Train AUC')\n",
    "plt.plot(k_neighbors, test_auc_list, label='Test AUC')\n",
    "plt.legend()\n",
    "plt.xlabel('# of Neighbors Considered in KNN Classifier')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test AUC appears to stop improving at k = ~150."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a TUNED KNN classifier (n_neighbors = 150)\n",
    "\n",
    "clf1b = KNeighborsClassifier(n_neighbors=150)\n",
    "clf1b.fit(X_train, y_train)\n",
    "\n",
    "y_hat_test = clf1b.predict(X_test)\n",
    "y_hat_train = clf1b.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check accuracy score and AUC score of TUNED KNN model\n",
    "\n",
    "train_test_acc_auc(X_train, X_test, y_train, y_test, y_hat_train, y_hat_test, clf=clf1b,\n",
    "                   multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check classification report for TUNED KNN model\n",
    "\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix for TUNED KNN model\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(clf1b, X_test, y_test, cmap='Blues', display_labels=labels.keys(),\n",
    "                      normalize='true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1b Interpretation\n",
    "After tuning the number of nearest neighbors (n_neighbors) to 150, the test accuracy and test AUC are slightly improved to 0.48 and 0.72, respectively.  \n",
    "\n",
    "The classifier correctly labeled 36% of True Home Wins, 62% of True Away Wins, and 57% of True Draws. \n",
    "\n",
    "Interestingly, the tuned KNN classifier is signficantly worse at correctly labeling True Home Wins than the vanilla KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2a: Vanilla Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train_test split on the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Synthetic Minority Over-Sampling Technique (SMOTE) to achieve class balance\n",
    "\n",
    "X_train, y_train = multi_class_SMOTE(\n",
    "    X_train, y_train, n=3, random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a vanilla Decision Tree classifier\n",
    "\n",
    "clf2a = DecisionTreeClassifier(random_state=42)\n",
    "clf2a.fit(X_train, y_train)\n",
    "\n",
    "y_hat_test = clf2a.predict(X_test)\n",
    "y_hat_train = clf2a.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy and AUC of vanilla Decision Tree classifier\n",
    "\n",
    "train_test_acc_auc(X_train, X_test, y_train, y_test, y_hat_train, y_hat_test, clf=clf2a,\n",
    "                   multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classification report of vanilla Decision Tree classifier\n",
    "\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix for vanilla Decision Tree Classifier\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(clf2a, X_test, y_test, cmap='Blues', display_labels=labels.keys(),\n",
    "                      normalize='true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2a Interpretation\n",
    "The vanilla Decision Tree classifier performs much better at this task than KNN, with an test prediction accuracy of 0.59 and a test AUC of 0.67. \n",
    "\n",
    "The classifier correctly labeled 67% of True Home Wins, 66% of True Away Wins, and 32% of True Draws.\n",
    "\n",
    "The classifier clearly has difficulty correcly predicting Draws, and often incorrectly predicts other results (Home Wins and Away Wins) as Draws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2b: Decision Tree with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train_test split on the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Synthetic Minority Over-Sampling Technique (SMOTE) to achieve class balance\n",
    "\n",
    "X_train, y_train = multi_class_SMOTE(\n",
    "    X_train, y_train, n=3, random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate initial DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameter grid for search (uncomment to run)\n",
    "\n",
    "# dt_param_grid = {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [None, 2, 3, 4, 5, 6, 8, 10, 12, 15],\n",
    "#     'min_samples_split': [2, 5, 10, 20, 30],\n",
    "#     'min_samples_leaf': [1, 2, 3, 4, 5, 6, 8, 10, 12],\n",
    "#     'max_features': [None, 1, 2, 5, 10, 15, 20, 30],\n",
    "#     'max_leaf_nodes': [None, 5, 10, 20]\n",
    "# }\n",
    "\n",
    "# # Instantiate GridSearchCV\n",
    "# dt_grid_search = GridSearchCV(dt_clf, dt_param_grid, cv=3, return_train_score=True, verbose=1)\n",
    "\n",
    "# # Fit to the data\n",
    "# dt_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize best parameters\n",
    "dt_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Decision Tree classifier using best_params from grid search\n",
    "\n",
    "clf2b = DecisionTreeClassifier(**dt_grid_search.best_params_,\n",
    "                               random_state=42)\n",
    "\n",
    "clf2b.fit(X_train, y_train)\n",
    "\n",
    "y_hat_test = clf2b.predict(X_test)\n",
    "y_hat_train = clf2b.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy and AUC of TUNED Decision Tree classifier\n",
    "\n",
    "train_test_acc_auc(X_train, X_test, y_train, y_test, y_hat_train, y_hat_test, clf=clf2b,\n",
    "                   multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classification report of TUNED Decision Tree classifier\n",
    "\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for tuned Decision Tree classifier\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(clf2b, X_test, y_test, cmap='Blues', display_labels=labels.keys(),\n",
    "                      normalize='true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2b Interpretation\n",
    "Hyperparameter tuning of the Decision Tree using GridSearchCV did not improve the classifier's test prediction accuracy (0.59), but did slightly improve the AUC score, from 0.67 (vanilla) to 0.73 (tuned).\n",
    "\n",
    "The classifier correctly labeled 65% of True Home Wins, 69% of True Away Wins, and 34% of True Draws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3a: Vanilla Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train_test_split on the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Synthetic Minority Over-Sampling Technique (SMOTE) to achieve class balance\n",
    "\n",
    "X_train, y_train = multi_class_SMOTE(\n",
    "    X_train, y_train, n=3, random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a vanilla Random Forest classifier\n",
    "\n",
    "clf3a = RandomForestClassifier(random_state=42)\n",
    "clf3a.fit(X_train, y_train)\n",
    "\n",
    "y_hat_test = clf3a.predict(X_test)\n",
    "y_hat_train = clf3a.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy and AUC of vanilla Random Forest classifier\n",
    "\n",
    "train_test_acc_auc(X_train, X_test, y_train, y_test, y_hat_train, y_hat_test, clf=clf3a,\n",
    "                   multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classification report of vanilla Random Forest classifier\n",
    "\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix for vanilla Random Forest classifier\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(clf3a, X_test, y_test, cmap='Blues', display_labels=labels.keys(),\n",
    "                      normalize='true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3a Interpretation\n",
    "The vanilla Random Forest Classifier increased overall test prediction accuracy to 0.63, and improved the test AUC score to 0.77. This is a significant performance increase over both the KNN and Decision Tree classifiers.\n",
    "\n",
    "The classifier correctly labeled 76% of True Home Wins, 70% of True Away Wins, and 25% of True Draws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3b: Random Forest with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train_test_split on the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Synthetic Minority Over-Sampling Technique (SMOTE) to achieve class balance\n",
    "\n",
    "X_train, y_train = multi_class_SMOTE(\n",
    "    X_train, y_train, n=3, random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameter grid for Random Forest search (uncomment to run)\n",
    "\n",
    "# rf_param_grid = {'criterion': ['gini', 'entropy'],\n",
    "#  'max_depth': [5, 10],\n",
    "#  'max_features': [None, 15, 20],\n",
    "#  'max_leaf_nodes': [None, 5],\n",
    "#  'min_samples_leaf': [1, 2, 5],\n",
    "#  'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# # Instantiate GridSearchCV\n",
    "# rf_grid_search = GridSearchCV(rf, rf_param_grid, cv=3, return_train_score=True, verbose=1)\n",
    "\n",
    "# # Fit to the data\n",
    "# rf_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize best parameters\n",
    "\n",
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Random Forest classifier using best_params\n",
    "\n",
    "clf3b = RandomForestClassifier(**rf_grid_search.best_params_,\n",
    "                               random_state=42)\n",
    "clf3b.fit(X_train, y_train)\n",
    "\n",
    "y_hat_test = clf3b.predict(X_test)\n",
    "y_hat_train = clf3b.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy and AUC of TUNED Random Forest classifier\n",
    "\n",
    "train_test_acc_auc(X_train, X_test, y_train, y_test, y_hat_train, y_hat_test, clf=clf3b,\n",
    "                   multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classification report of TUNED Random Forest classifier\n",
    "\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for TUNED Random Forest classifier\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(clf3b, X_test, y_test, cmap='Blues', display_labels=labels.keys(),\n",
    "                      normalize='true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3b Interpretation\n",
    "The tuned Random Forest Classifier increased overall test prediction accuracy to 0.71, and improved the test AUC score to 0.83. This is a significant performance increase over the vanilla Random Forest Classifier.\n",
    "\n",
    "The classifier correctly labeled 83% of True Home Wins, 77% of True Away Wins, and 36% of True Draws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4A: Vanilla Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train_test split on the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Synthetic Minority Over-Sampling Technique (SMOTE) to achieve class balance\n",
    "\n",
    "X_train, y_train = multi_class_SMOTE(\n",
    "    X_train, y_train, n=3, random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a vanilla AdaBoost classifier\n",
    "\n",
    "clf4a = AdaBoostClassifier(random_state=42)\n",
    "clf4a.fit(X_train, y_train)\n",
    "\n",
    "y_hat_test = clf4a.predict(X_test)\n",
    "y_hat_train = clf4a.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy and AUC of vanilla AdaBoost classifier\n",
    "\n",
    "train_test_acc_auc(X_train, X_test, y_train, y_test, y_hat_train, y_hat_test, clf=clf4a,\n",
    "                   multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classification report of vanilla AdaBoost classifier\n",
    "\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix for vanilla AdaBoost classifier\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(clf4a, X_test, y_test, cmap='Blues', display_labels=labels.keys(),\n",
    "                      normalize='true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4a Interpretation\n",
    "The vanilla AdaBoost Classifier slightly increased overall test prediction accuracy to 0.74, and improved the test AUC score to 0.84. This is a slight performance increase over tuned Random Forest Classifier.\n",
    "\n",
    "The classifier correctly labeled 79% of True Home Wins, 71% of True Away Wins, and 66% of True Draws.\n",
    "\n",
    "The vanilla AdaBoost Classifier is significantly better than previous models at correctly predicting True Draws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4b: Adaboost with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train_test split on the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Synthetic Minority Over-Sampling Technique (SMOTE) to achieve class balance\n",
    "\n",
    "X_train, y_train = multi_class_SMOTE(\n",
    "    X_train, y_train, n=3, random_state=42, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Adaboost Classifier\n",
    "\n",
    "ada = AdaBoostClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Parameter grid for Random Forest search (uncomment to run)\n",
    "\n",
    "# ada_param_grid = {'n_estimators': [50, 75, 100, 125],\n",
    "#                  'learning_rate': [0.1, 0.5, 1.0, 1.5, 3],\n",
    "#                  'algorithm': ['SAMME', 'SAMME.R']}\n",
    "\n",
    "# # Instantiate GridSearchCV\n",
    "# ada_grid_search = GridSearchCV(ada, ada_param_grid, cv=3, scoring='accuracy', verbose=2)\n",
    "\n",
    "# # Fit to the data\n",
    "# ada_grid_search.fit(X_train_sm2, y_train_sm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize best parameters\n",
    "\n",
    "ada_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an AdaBoost Classifier using best_params\n",
    "\n",
    "clf4b = AdaBoostClassifier(**ada_grid_search.best_params_,\n",
    "                           random_state=42)\n",
    "\n",
    "clf4b.fit(X_train, y_train)\n",
    "\n",
    "y_hat_test = clf4b.predict(X_test)\n",
    "y_hat_train = clf4b.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy and AUC of TUNED AdaBoost classifier\n",
    "\n",
    "train_test_acc_auc(X_train, X_test, y_train, y_test, y_hat_train, y_hat_test, clf=clf4b,\n",
    "                   multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classification report of TUNED Random Forest classifier\n",
    "\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for tuned KNN model\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(clf4b, X_test, y_test, cmap='Blues', display_labels=labels.keys(),\n",
    "                      normalize='true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4b Interpretation\n",
    "The tuned AdaBoost Classifier performance is almost identical to, but slightly lower than, the vanilla AdaBoost Classifier, with a test accuracy of 0.73 and a test AUC of 0.82.\n",
    "\n",
    "The classifier correctly labeled 77% of True Home Wins, 70% of True Away Wins, and 69% of True Draws.\n",
    "\n",
    "The AdaBoost classifier clearly does not benefit very much (if at all) from hyperparameter tuning in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5a: Vanilla XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train_test split on the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Synthetic Minority Over-Sampling Technique (SMOTE) to achieve class balance\n",
    "\n",
    "X_train, y_train = multi_class_SMOTE(\n",
    "    X_train, y_train, n=3, random_state=42, verbose=2)\n",
    "\n",
    "# Must convert X_train_sm2 back to df to use in XGBoost\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a vanilla XGBoost classifier\n",
    "\n",
    "clf5a = XGBClassifier(random_state=42)\n",
    "clf5a.fit(X_train, y_train)\n",
    "\n",
    "y_hat_test = clf5a.predict(X_test)\n",
    "y_hat_train = clf5a.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy and AUC of vanilla XGBoost classifier\n",
    "\n",
    "train_test_acc_auc(X_train, X_test, y_train, y_test, y_hat_train, y_hat_test, clf=clf5a,\n",
    "                   multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classification report of vanilla XGBoost classifier\n",
    "\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix for vanilla XGBoost classifier\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(clf5a, X_test, y_test, cmap='Blues', display_labels=labels.keys(),\n",
    "                      normalize='true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 5a Interpretation\n",
    "The vanilla XGBoost Classifier performance is generally a significant improvement over previous models, with a test accuracy of 0.79 and a test AUC of 0.90.\n",
    "\n",
    "The classifier correctly labeled 90% of True Home Wins, 88% of True Away Wins, and 44% of True Draws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5b: XGBoost with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a train_test split on the data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Synthetic Minority Over-Sampling Technique (SMOTE) to achieve class balance\n",
    "\n",
    "X_train, y_train = multi_class_SMOTE(\n",
    "    X_train, y_train, n=3, random_state=42, verbose=2)\n",
    "\n",
    "# Must convert X_train_sm2 back to df to use in XGBoost\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGBoost Classifier\n",
    "\n",
    "xg = XGBClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Parameter grid for XGBoost search (uncomment to run)\n",
    "\n",
    "# xg_param_grid = {\n",
    "#     'learning_rate': [0.01, 0.1, 1],\n",
    "#     'max_depth': [5, 7, 9, 12],\n",
    "#     'min_child_weight': [1, 2, 3],\n",
    "#     'n_estimators': [50, 100, 125],\n",
    "#     'subsample': [0.5, 0.75, 1.0]\n",
    "# }\n",
    "\n",
    "# # Instantiate GridSearchCV\n",
    "# xg_grid_search = GridSearchCV(\n",
    "#     xg, xg_param_grid, scoring='accuracy', verbose=2)\n",
    "\n",
    "# # Fit to the data\n",
    "# xg_grid_search.fit(X_train_sm2, y_train_sm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize best parameters\n",
    "\n",
    "xg_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an XGBoost Classifier using best_params\n",
    "\n",
    "clf5b = XGBClassifier(**xg_grid_search.best_params_,\n",
    "                      random_state=42)\n",
    "\n",
    "clf5b.fit(X_train, y_train)\n",
    "\n",
    "y_hat_test = clf5b.predict(X_test)\n",
    "y_hat_train = clf5b.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy and AUC of TUNED XGBoost classifier\n",
    "\n",
    "train_test_acc_auc(X_train, X_test, y_train, y_test, y_hat_train, y_hat_test, clf=clf5b,\n",
    "                   multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classification report of TUNED XGBoost classifier\n",
    "\n",
    "print(classification_report(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for tuned XGBoost model\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plot_confusion_matrix(clf5b, X_test, y_test, cmap='Blues', display_labels=labels.keys(),\n",
    "                      normalize='true', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 5b Interpretation\n",
    "The tuned XGBoost Classifier performance is almost identical to, but slightly lower than, the vanilla XGBoost Classifier, with a test accuracy of 0.78 and a test AUC of 0.88.\n",
    "\n",
    "The classifier correctly labeled 90% of True Home Wins, 92% of True Away Wins, and 32% of True Draws.\n",
    "\n",
    "The XGBoost classifier clearly does not benefit very much (if at all) from hyperparameter tuning in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Classifier Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Classifier              |Train Accuracy|Train AUC|Test Accuracy|Test AUC|\n",
    "|------------------------|--------------|---------|-------------|--------|\n",
    "|KNN (vanilla)           |0.79          |0.94     |0.43         |0.63    |\n",
    "|KNN (tuned)             |0.53          |0.75     |0.48         |0.72    |\n",
    "|Decision Tree (vanilla) |1.0           |1.0      |0.59         |0.67    |\n",
    "|Decision Tree (tuned)   |0.89          |0.98     |0.59         |0.73    |\n",
    "|Random Forest (vanilla) |1.0           |1.0      |0.63         |0.77    |\n",
    "|Random Forest (tuned)   |1.0           |1.0      |0.71         |0.83    |\n",
    "|AdaBoost (vanilla)      |0.76          |0.88     |0.74         |0.84    |\n",
    "|AdaBoost (tuned)        |0.81          |0.89     |0.73         |0.82    |\n",
    "|XGBoost (vanilla)       |0.93          |0.99     |0.79         |0.90    |\n",
    "|XGBoost (tuned)         |1.0           |1.0      |0.78         |0.88    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "423px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
